{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformações RDD e ações\n",
    "\n",
    "Nesta palestra, começaremos a aprofundar o uso de Spark e Python. Por favor, veja os videos para uma explicação completa.\n",
    "\n",
    "## Termos importantes\n",
    "\n",
    "Vamos rapidamente passar por alguns termos importantes:\n",
    "\n",
    "Termo                  |Definição\n",
    "----                   |-------\n",
    "RDD                    |Resilient Distributed Dataset\n",
    "Transformação          |Operação Spark que produz um RDD\n",
    "Ação                   |Operação Spark que produz um objeto local\n",
    "Spark Job              |Sequência de transformações em dados com uma ação final\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando um RDD\n",
    "\n",
    "Existem duas formas comuns de criar um RDD:\n",
    "\n",
    "Método                                   |Resultado\n",
    "----------                               |-------\n",
    "`sc.parallelize(array)`                  |Cria um array de elementos RDD\n",
    "`sc.textFile(path/to/file)`                      |Cria um RDD de linhas de um arquivo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformação RDD\n",
    "\n",
    "Podemos usar transformações para criar um conjunto de instruções que queremos executar no RDD (antes de chamar uma ação e realmente executá-las).\n",
    "\n",
    "Exemplo de Transformação | Resultado\n",
    "----------                               |-------\n",
    "`filter(lambda x: x % 2 == 0)`           |Descarte elementos não-pares\n",
    "`map(lambda x: x * 2)`                   |Multiplica cada elemento RDD por `2`\n",
    "`map(lambda x: x.split())`               |Divida cada string em palavras\n",
    "`flatMap(lambda x: x.split())`           |Divide cada string em palavras e aplique a seqüência\n",
    "`sample(withReplacement=True,0.25)`      |Crie uma amostra de 25% dos elementos com substituição\n",
    "`union(rdd)`                             |Anexar `rdd` ao RDD existente\n",
    "`distinct()`                             |Remover duplicatas no RDD\n",
    "`sortBy(lambda x: x, ascending=False)`   |Classificar elementos em ordem decrescente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ações RDD\n",
    "\n",
    "Depois de ter sua \"receita\" de transformações pronta, o que você fará em seguida é executá-las chamando uma ação. Aqui estão algumas ações comuns:\n",
    "\n",
    "Ação                             |Resultado\n",
    "----------                             |-------\n",
    "`collect()`                            |Converta o RDD em uma lista na memória\n",
    "`take(3)`                              |Pega os 3 primeiros elementos do RDD\n",
    "`top(3)`                               |Pega os top 3 elementos do RDD\n",
    "`takeSample(withReplacement=True,3)`   |Crie uma amostra de 3 elementos com substituição\n",
    "`sum()`                                |Soma (Assume elementos numéricos)\n",
    "`mean()`                               |Média (Assume elementos numéricos)\n",
    "`stdev()`                              |Desvio padrão (Assume elementos numéricos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "# Exemplos\n",
    "\n",
    "Agora, a melhor maneira de mostrar tudo isso é através de exemplos! Primeiro, revisaremos um pouco criando e trabalhando com um arquivo de texto simples, então passaremos a dados mais realistas, como clientes e dados de vendas.\n",
    "\n",
    "### Criando um RDD a partir de um arquivo de texto:\n",
    "\n",
    "** Criando o arquivo de texto **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting example2.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile example2.txt\n",
    "first \n",
    "second line\n",
    "the third line\n",
    "then a fourth line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos realizar algumas transformações e ações neste arquivo de texto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Java gateway process exited before sending the driver its port number",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-4443dd5159b0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pyspark\\context.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls)\u001b[0m\n\u001b[0;32m    113\u001b[0m         \"\"\"\n\u001b[0;32m    114\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callsite\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfirst_spark_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mCallSite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m         \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgateway\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgateway\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    116\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m             self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pyspark\\context.py\u001b[0m in \u001b[0;36m_ensure_initialized\u001b[1;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[0;32m    281\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gateway\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 283\u001b[1;33m                 \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gateway\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgateway\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mlaunch_gateway\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    284\u001b[0m                 \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jvm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gateway\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjvm\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pyspark\\java_gateway.py\u001b[0m in \u001b[0;36mlaunch_gateway\u001b[1;34m(conf)\u001b[0m\n\u001b[0;32m     93\u001b[0m                 \u001b[0mcallback_socket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mgateway_port\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Java gateway process exited before sending the driver its port number\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m         \u001b[1;31m# In Windows, ensure the Java child processes do not linger after Python has exited.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mException\u001b[0m: Java gateway process exited before sending the driver its port number"
     ]
    }
   ],
   "source": [
    "sc = SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-3edc8410ff37>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Mostra o RDD\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtextFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'example2.txt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'sc' is not defined"
     ]
    }
   ],
   "source": [
    "# Mostra o RDD\n",
    "sc.textFile('example2.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save a reference to this RDD\n",
    "text_rdd = sc.textFile('example2.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['first'],\n",
       " ['second', 'line'],\n",
       " ['the', 'third', 'line'],\n",
       " ['then', 'a', 'fourth', 'line']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Map a function (or lambda expression) to each line\n",
    "# Then collect the results.\n",
    "text_rdd.map(lambda line: line.split()).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map vs flatMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['first',\n",
       " 'second',\n",
       " 'line',\n",
       " 'the',\n",
       " 'third',\n",
       " 'line',\n",
       " 'then',\n",
       " 'a',\n",
       " 'fourth',\n",
       " 'line']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Collect everything as a single flat map\n",
    "text_rdd.flatMap(lambda line: line.split()).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RDDs and Key Value Pairs\n",
    "\n",
    "Now that we've worked with RDDs and how to aggregate values with them, we can begin to look into working with Key Value Pairs. In order to do this, let's create some fake data as a new text file.\n",
    "\n",
    "This data represents some services sold to customers for some SAAS business."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing services.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile services.txt\n",
    "#EventId    Timestamp    Customer   State    ServiceID    Amount\n",
    "201       10/13/2017      100       NY       131          100.00\n",
    "204       10/18/2017      700       TX       129          450.00\n",
    "202       10/15/2017      203       CA       121          200.00\n",
    "206       10/19/2017      202       CA       131          500.00\n",
    "203       10/17/2017      101       NY       173          750.00\n",
    "205       10/19/2017      202       TX       121          200.00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "services = sc.textFile('services.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#EventId    Timestamp    Customer   State    ServiceID    Amount',\n",
       " '201       10/13/2017      100       NY       131          100.00']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "services.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[10] at RDD at PythonRDD.scala:43"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "services.map(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['#EventId', 'Timestamp', 'Customer', 'State', 'ServiceID', 'Amount'],\n",
       " ['201', '10/13/2017', '100', 'NY', '131', '100.00'],\n",
       " ['204', '10/18/2017', '700', 'TX', '129', '450.00']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "services.map(lambda x: x.split()).take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's remove that first hash-tag!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['EventId    Timestamp    Customer   State    ServiceID    Amount',\n",
       " '201       10/13/2017      100       NY       131          100.00',\n",
       " '204       10/18/2017      700       TX       129          450.00',\n",
       " '202       10/15/2017      203       CA       121          200.00',\n",
       " '206       10/19/2017      202       CA       131          500.00',\n",
       " '203       10/17/2017      101       NY       173          750.00',\n",
       " '205       10/19/2017      202       TX       121          200.00']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "services.map(lambda x: x[1:] if x[0]=='#' else x).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['EventId', 'Timestamp', 'Customer', 'State', 'ServiceID', 'Amount'],\n",
       " ['201', '10/13/2017', '100', 'NY', '131', '100.00'],\n",
       " ['204', '10/18/2017', '700', 'TX', '129', '450.00'],\n",
       " ['202', '10/15/2017', '203', 'CA', '121', '200.00'],\n",
       " ['206', '10/19/2017', '202', 'CA', '131', '500.00'],\n",
       " ['203', '10/17/2017', '101', 'NY', '173', '750.00'],\n",
       " ['205', '10/19/2017', '202', 'TX', '121', '200.00']]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "services.map(lambda x: x[1:] if x[0]=='#' else x).map(lambda x: x.split()).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Key Value Pairs for Operations\n",
    "\n",
    "Let us now begin to use methods that combine lambda expressions that use a ByKey argument. These ByKey methods will assume that your data is in a Key,Value form. \n",
    "\n",
    "\n",
    "For example let's find out the total sales per state: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# From Previous\n",
    "cleanServ = services.map(lambda x: x[1:] if x[0]=='#' else x).map(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['EventId', 'Timestamp', 'Customer', 'State', 'ServiceID', 'Amount'],\n",
       " ['201', '10/13/2017', '100', 'NY', '131', '100.00'],\n",
       " ['204', '10/18/2017', '700', 'TX', '129', '450.00'],\n",
       " ['202', '10/15/2017', '203', 'CA', '121', '200.00'],\n",
       " ['206', '10/19/2017', '202', 'CA', '131', '500.00'],\n",
       " ['203', '10/17/2017', '101', 'NY', '173', '750.00'],\n",
       " ['205', '10/19/2017', '202', 'TX', '121', '200.00']]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleanServ.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('State', 'Amount'),\n",
       " ('NY', '100.00'),\n",
       " ('TX', '450.00'),\n",
       " ('CA', '200.00'),\n",
       " ('CA', '500.00'),\n",
       " ('NY', '750.00'),\n",
       " ('TX', '200.00')]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's start by practicing grabbing fields\n",
    "cleanServ.map(lambda lst: (lst[3],lst[-1])).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('State', 'Amount'),\n",
       " ('NY', '100.00750.00'),\n",
       " ('TX', '450.00200.00'),\n",
       " ('CA', '200.00500.00')]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Continue with reduceByKey\n",
    "# Notice how it assumes that the first item is the key!\n",
    "cleanServ.map(lambda lst: (lst[3],lst[-1]))\\\n",
    "         .reduceByKey(lambda amt1,amt2 : amt1+amt2)\\\n",
    "         .collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uh oh! Looks like we forgot that the amounts are still strings! Let's fix that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('State', 'Amount'), ('NY', 850.0), ('TX', 650.0), ('CA', 700.0)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Continue with reduceByKey\n",
    "# Notice how it assumes that the first item is the key!\n",
    "cleanServ.map(lambda lst: (lst[3],lst[-1]))\\\n",
    "         .reduceByKey(lambda amt1,amt2 : float(amt1)+float(amt2))\\\n",
    "         .collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can continue our analysis by sorting this output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('NY', 850.0), ('CA', 700.0), ('TX', 650.0)]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grab state and amounts\n",
    "# Add them\n",
    "# Get rid of ('State','Amount')\n",
    "# Sort them by the amount value\n",
    "cleanServ.map(lambda lst: (lst[3],lst[-1]))\\\n",
    ".reduceByKey(lambda amt1,amt2 : float(amt1)+float(amt2))\\\n",
    ".filter(lambda x: not x[0]=='State')\\\n",
    ".sortBy(lambda stateAmount: stateAmount[1], ascending=False)\\\n",
    ".collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Remember to try to use unpacking for readability. For example: **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = ['ID','State','Amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def func1(lst):\n",
    "    return lst[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def func2(id_st_amt):\n",
    "    # Unpack Values\n",
    "    (Id,st,amt) = id_st_amt\n",
    "    return amt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Amount'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func1(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Amount'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func2(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Great Job!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
